model:
  name_or_path: Qwen/Qwen3-1.7B
  trust_remote_code: true
  torch_dtype: bfloat16
  tokenizer_name: Qwen/Qwen3-1.7B
dataset:
  name: glue
  subset: cola
  train_split: train
  eval_split: validation
  text_fields:
  - sentence
  label_field: label
  max_length: 128
adapter:
  method: mam
  target_modules: []
  rank: 8
  alpha: 8.0
  dropout: 0.05
  init_scale: 1.0
  train_bias: false
runtime:
  seed: 11
  gradient_checkpointing: true
  torch_compile: false
wandb:
  enabled: true
  project: peft-playground
  name: qwen3-cola-lora
  tags:
  - glue
  - cola
  - lora
  - qwen3
ddp:
  enabled: true
  backend: nccl
  gradient_accumulation_steps: 1
  find_unused_parameters: false
  broadcast_buffers: true
  static_graph: false
train:
  output_dir: outputs/qwen_cola_mam
  num_epochs: 50
  per_device_batch_size: 128
  gradient_accumulation_steps: 1
  warmup_ratio: 0.05
  learning_rate: 0.00012
  weight_decay: 0.01
  max_steps: null
  precision:
    fp16: false
    bf16: true
  logging_steps: 50
evaluation:
  per_device_batch_size: 128
  strategy: steps
  steps: 50
  save_strategy: steps
  save_steps: 50
  load_best_model_at_end: true
  metric_for_best_model: matthews_correlation
  greater_is_better: true
  do_train: true
  do_eval: true
