model:
  name_or_path: Qwen/Qwen3-1.7B
  trust_remote_code: true
  torch_dtype: bfloat16
  tokenizer_name: Qwen/Qwen3-1.7B

dataset:
  name: glue
  subset: cola
  train_split: train
  eval_split: validation
  text_fields: [sentence]
  label_field: label
  max_length: 128

adapter:
  method: lora
  target_modules: []
  rank: 4
  alpha: 8.0
  dropout: 0.05
  init_scale: 1.0
  train_bias: false

trainer:
  output_dir: outputs/qwen_cola_lora
  num_train_epochs: 10.0
  per_device_train_batch_size: 4
  per_device_eval_batch_size: 8
  gradient_accumulation_steps: 16
  warmup_ratio: 0.05
  learning_rate: 1.2e-4
  weight_decay: 0.01
  eval_strategy: steps
  eval_steps: 50
  save_strategy: steps
  save_steps: 50
  logging_steps: 25
  max_steps: null
  fp16: false
  bf16: true
  report_to: [none]
  extra:
    do_train: true
    do_eval: true
    load_best_model_at_end: true
    metric_for_best_model: matthews_correlation
    greater_is_better: true

runtime:
  seed: 11
  gradient_checkpointing: true
  torch_compile: false

wandb:
  enabled: true
  project: peft-playground
  name: qwen3-cola-lora
  tags: [glue, cola, lora, qwen3]
